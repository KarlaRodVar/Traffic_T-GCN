{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUNEF\n",
    "### Trabajo de Final de Master "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Modelado y Análisis de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerias que van a ser utilizados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph.layer import GCN_LSTM\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import  Model\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion definida para realizar la ventana de los datos con los que se van a trabajar\n",
    "\n",
    "def sequence_data_preparation_predict(seq_len, pre_len, test_data_pred):\n",
    "    testX_pred = []\n",
    "\n",
    "    for i in range(test_data_pred.shape[1] - int(seq_len + pre_len - 1)):\n",
    "        b = test_data_pred[:, i : i + seq_len + pre_len]\n",
    "        testX_pred.append(b[:, :seq_len])\n",
    "\n",
    "    testX_pred = np.array(testX_pred)\n",
    "\n",
    "    return testX_pred\n",
    "\n",
    "def extract_metrics_from_predicted(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred).round(2)\n",
    "    rmse = np.sqrt(mse).round(2)\n",
    "    mae = mean_absolute_error(y_true, y_pred).round(2)\n",
    "    mape =np.mean(np.abs((y_true - y_pred) / y_true)* 100).round(2)\n",
    "    return (f'mse :{mse}, rmse: {rmse}, mae: {mae}, mape: {mape}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importamos los datos a trabajar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan los datos tratados previamente en pasos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos temporales sobre intensidad de tráfico\n",
    "trainX=np.load('../datos/03_procesados/trainX.npy')\n",
    "trainY=np.load('../datos/03_procesados/trainY.npy')\n",
    "valX=np.load('../datos/03_procesados/valX.npy')\n",
    "valY=np.load('../datos/03_procesados/valY.npy')\n",
    "testX=np.load('../datos/03_procesados/testX.npy')\n",
    "testY=np.load('../datos/03_procesados/testY.npy')\n",
    "val_11=np.load('../datos/03_procesados/pred_11.npy')\n",
    "\n",
    "test_scaled=np.load('../datos/03_procesados/test_scaled.npy')\n",
    "\n",
    "# Datos Espaciales sobre la localización de sensores\n",
    "matrix_lat_long = pickle.load(open('../datos/04_pickles/matrix_lat_long_final', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creamos el modelo de Predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se crea la arquitectura del modelo de predicción utilizado en base a la información proporcionada por la librería StellarGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=10,\n",
    "    adj=matrix_lat_long,\n",
    "    gc_layer_sizes=[16, 10],\n",
    "    gc_activations=[\"relu\", \"relu\"],\n",
    "    lstm_layer_sizes=[200,200],\n",
    "    lstm_activations=[\"tanh\", \"tanh\"],\n",
    "    dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builds a GCN model for node  feature prediction\n",
    "x_input, x_output = gcn_lstm.in_out_tensors()\n",
    "\n",
    "model = Model(inputs=x_input, outputs=x_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos el optimizador a utilizar y el ratio de aprendizaje\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=\"mae\", metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo creado con los datos de train y verificamos la funcion de perdida con los datos de validacion\n",
    "history = model.fit(\n",
    "    trainX,\n",
    "    trainY,\n",
    "    epochs=200,\n",
    "    batch_size=60,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(valX, valY),\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos la arquitectura de la red neuronal realizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('model_plot.png')\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Train loss: \",\n",
    "    history.history[\"loss\"][-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de función de pérdida\n",
    "sg.utils.plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Creación de predicciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primera prediccion de valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera prediccion se realiza tomando como entrada los 10 valores separados en el dataset de testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la primera predicción del modelo\n",
    "\n",
    "train_pred = model.predict(trainX)\n",
    "pred_1= model.predict(testX)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda prediccion de valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la segunda predicción de 30 min tomamos el valor de la primera predicción realizada y agregamos a los datos de entrenamiento para con los 10 valores (9 valores pasados y 1 valor de la predicción 1) predecimos los siguientes 30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiamos el dataset escalado original\n",
    "test_data_2=test_scaled.copy()\n",
    "test_data_2=pd.DataFrame(test_data_2)\n",
    "val_10=test_data_2.iloc[:,-1] # nos quedamos con el valor 10 de la serie de textX\n",
    "test_data_2=test_data_2.drop([0,10],axis=1)\n",
    "\n",
    "# Introducimos el valor predicho anteriormente\n",
    "list_pred=pd.DataFrame(pred_1)\n",
    "test_data_2['pred_10']=list_pred.T\n",
    "test_data_2['pred_data']=0\n",
    "\n",
    "# Pasamos los datos a array, formato que trabaja el modelo\n",
    "test_data_pred = np.array(test_data_2)\n",
    "\n",
    "# Colocamos los datos con la ventana de observaciones con las que vamos a trabajar\n",
    "testX_pred = sequence_data_preparation_predict(10, 1, test_data_pred)\n",
    "testX_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la prediccion con un nuevo dataset de 10 valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2=  model.predict(testX_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La nueva predicción la guardamos como un dataframe\n",
    "list_pred=pd.DataFrame(pred_2)\n",
    "\n",
    "# Hacemos una copia del dataframe pasado y agregamos la segunda predicción realizada\n",
    "df_pred=test_data_2.copy()\n",
    "df_pred['pred_11']=list_pred.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Viasualizamos valores reales y valores de resultado en las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertamos los valores reales de las predicciones 1 y 2 al nuevo dataframe\n",
    "df_pred[10]=val_10\n",
    "df_pred[11]=val_11\n",
    "\n",
    "# Ordenamos las columnas del nuevo dataframe\n",
    "col_order=[1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,'pred_10','pred_11']\n",
    "df_pred=df_pred[col_order]\n",
    "df_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores normalizados los re-escalamos para trabajar con el rango inicial de intensidad de tráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos valor minimo y máximo definido para el proceso de re-escalado\n",
    "max_speed = 10715.0\n",
    "min_speed= 0\n",
    "\n",
    "# Reescalamos la tabla resultante de valores real vs predicciones\n",
    "df_pred = df_pred * (max_speed - min_speed) + min_speed\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Métricas de salida de valores predichos por red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las variables con las vamos a comparar las predicciones\n",
    "y_true_0=df_pred.loc[:,10]\n",
    "y_true_1=df_pred.loc[:,11]\n",
    "\n",
    "y_pred_0=df_pred.loc[:,'pred_10']\n",
    "y_pred_1=df_pred.loc[:,'pred_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Salida de la segunda prediccion {extract_metrics_from_predicted(y_true_0, y_pred_0)}')\n",
    "print(f'Salida de la primera prediccion {extract_metrics_from_predicted(y_true_1, y_pred_1)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Comparando el modelo de redes neuronales utilizando un modelo base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un modelo base el cual tome el valor anterior de la serie temporal com predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos todos los datos de intensidad de sensores\n",
    "pred_speed_data=pd.read_csv(\"../datos/03_procesados/datos_procesados.csv\", index_col='id')\n",
    "pred_speed_data['-1']=pred_speed_data.iloc[:,0]\n",
    "\n",
    "# Cambio el orden de las columnas para que el primer dato (columna -1) quede en la parte inicial del dataframe\n",
    "cols = pred_speed_data.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "\n",
    "base_model=pred_speed_data[cols].iloc[:,:-1]\n",
    "base_model=base_model.reset_index()\n",
    "b_m=base_model.drop(['id'], axis=1)\n",
    "b_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_pred_0=b_m.iloc[:,-2]\n",
    "bs_pred_1=b_m.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Salida de la primera prediccion {extract_metrics_from_predicted(y_true_0, bs_pred_0)}')\n",
    "print(f'Salida de la segunda prediccion {extract_metrics_from_predicted(y_true_1, bs_pred_1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de comportamiento de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seran seleccionados un conjunto de sensores apra ver su comportamiento en relacion a los datos reales, el modelo base creado y el modelo T-GCN con ffin de evaluar su desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se seleccionan los IDs a evaluar\n",
    "list_id=[4009, 4005, 4011, 4024, 3994, 10100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los dataframes los que serán trabajados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo los datos reales con los que vamos a trabajar\n",
    "real_caso=pd.read_csv(\"../datos/03_procesados/datos_procesados.csv\")\n",
    "real_caso=real_caso[real_caso['id'].isin(list_id)].set_index(['id'])\n",
    "real_caso=real_caso.iloc[:,10:9398]\n",
    "\n",
    "# Coloco el modelo base con las condiciones para poder realizar la comparacion, seleccionando los sensores a evaluar\n",
    "bm_caso=base_model[base_model['id'].isin(list_id)].set_index(['id'])\n",
    "bm_caso=bm_caso.iloc[:,10:9398]\n",
    "\n",
    "# Trabajamos los datos de la salida del modelo NN para realizar las comparaciones\n",
    "max_speed = 10715\n",
    "pre_model=pd.DataFrame(train_pred)\n",
    "\n",
    "pre_model=(pre_model*max_speed).T #multiplicamos por el valor maximo de los datos del modelo y buscamos su transpuesta\n",
    "pre_model['id']=base_model['id'] # Los datos no presentan el id del sensor, se busca para ingresarlos\n",
    "pm_caso=pre_model[pre_model['id'].isin(list_id)]\n",
    "pm_caso=pm_caso.set_index(['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificamos las gráficas de salida para cada modelo creado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico para sensor 4005 en posición 2 del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se selcciona el intervalo a analizar\n",
    "indices = range(1, 200)\n",
    "\n",
    "# Se crea el gráfico para los datos reales y la comparación con los modelos\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(real_caso.columns[indices], real_caso.iloc[2, indices], color='red', label='Real')\n",
    "plt.plot(real_caso.columns[indices], bm_caso.iloc[2, indices], label='Modelo base')\n",
    "plt.plot(real_caso.columns[indices], pm_caso.iloc[2, indices], color='green', label='Modelo NN')\n",
    "\n",
    "multiples_of_10 = np.arange(10, 200, 10)\n",
    "\n",
    "plt.xticks(real_caso.columns[multiples_of_10])  # Establecer marcas solo en múltiplos de 10\n",
    "plt.legend()\n",
    "plt.title(f'Gráfico comparativo resultados de modelos de predicción tráfico para sensor 4005')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico para sensor 4009 en posición 3 del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se selcciona el intervalo a analizar\n",
    "indices = range(1, 200)\n",
    "\n",
    "# Se crea el gráfico para los datos reales y la comparación con los modelos\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(real_caso.columns[indices], real_caso.iloc[3, indices], color='red', label='Real')\n",
    "plt.plot(real_caso.columns[indices], bm_caso.iloc[3, indices], label='Modelo base')\n",
    "plt.plot(real_caso.columns[indices], pm_caso.iloc[3, indices], color='green', label='Modelo NN')\n",
    "\n",
    "multiples_of_10 = np.arange(10, 200, 10)\n",
    "\n",
    "plt.xticks(real_caso.columns[multiples_of_10])  # Establecer marcas solo en múltiplos de 10\n",
    "plt.title(f'Gráfico comparativo resultados de modelos de predicción tráfico para sensor 4009')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico para sensor 10100 en posición 5 del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se selcciona el intervalo a analizar\n",
    "indices = range(1, 200)\n",
    "\n",
    "# Se crea el gráfico para los datos reales y la comparación con los modelos\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(real_caso.columns[indices], real_caso.iloc[5, indices], color='red', label='Real')\n",
    "plt.plot(real_caso.columns[indices], bm_caso.iloc[5, indices], label='Modelo base')\n",
    "plt.plot(real_caso.columns[indices], pm_caso.iloc[5, indices], color='green', label='Modelo NN')\n",
    "\n",
    "multiples_of_10 = np.arange(10, 200, 10)\n",
    "\n",
    "plt.xticks(real_caso.columns[multiples_of_10])  # Establecer marcas solo en múltiplos de 10\n",
    "plt.title(f'Gráfico comparativo resultados de modelos de predicción tráfico para sensor 10100')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
